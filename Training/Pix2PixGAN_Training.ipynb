{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes for Training the Pix2Pix GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from numpy import inf\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import h5py\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data and print its shape\n",
    "\n",
    "mat = h5py.File('ALL_TRAIN_1000.mat', 'r')\n",
    "data = np.array(mat['all_multi_all'])\n",
    "target = np.array(mat['all_envdb_norm_all'])\n",
    "target = np.expand_dims(target, axis=1)\n",
    "\n",
    "print('RAW data: ', data.shape)\n",
    "print('Label images: ', target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "EPOCH = 200\n",
    "BATCH_SIZE = 8\n",
    "LR = 0.0001        # learning rate\n",
    "\n",
    "torch_data = torch.from_numpy(data)\n",
    "torch_delayed = torch.from_numpy(target)\n",
    "train_dataset = TensorDataset(torch_data, torch_delayed)\n",
    "\n",
    "# DataLoader for easy mini-batch return in training.\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_real(real):\n",
    "    avg = torch.sum(real, dim=1)/real.shape[1]\n",
    "    avg = avg.unsqueeze(1)\n",
    "    \n",
    "    return avg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pix2Pix GAN generator implementation\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=3, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    # torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Sigmoid(),\n",
    "                    )\n",
    "            return block\n",
    "        \n",
    "    def bottle_neck(self, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=256, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=512, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Generator, self).__init__()\n",
    "        #Encode\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.bottle_neck()\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_pool1 = self.dropout(encode_pool1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_pool2 = self.dropout(encode_pool2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        encode_pool3 = self.dropout(encode_pool3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        decode_block3 = self.dropout(decode_block3)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        decode_block2 = self.dropout(decode_block2)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        decode_block1 = self.dropout(decode_block1)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        return  final_layer\n",
    "    \n",
    "model_g = Generator(in_channel=128, out_channel=1).cuda()\n",
    "criterion_g = nn.L1Loss().cuda()\n",
    "optimizer_g = torch.optim.Adam(model_g.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "scheduler_g = torch.optim.lr_scheduler.StepLR(optimizer_g, step_size=50, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pix2Pix GAN [image] discriminator implementation\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(  \n",
    "            nn.Conv2d(2, 16, 4, stride=(2,2), padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(16, 64, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, stride=(2,4), padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(512, 1, 4, 1, padding=1),  \n",
    "            nn.Sigmoid()                \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output\n",
    "\n",
    "model_d = Discriminator().cuda()\n",
    "criterion_d = nn.BCELoss().cuda()\n",
    "optimizer_d = torch.optim.Adam(model_d.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.3)\n",
    "\n",
    "# Summary of the image discriminator architecture.\n",
    "summary_d = summary(model_d, input_data=(2, 128, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pix2Pix GAN [patch] discriminator implementation\n",
    "\n",
    "class Patch_Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Patch_Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(  \n",
    "            nn.Conv2d(2, 16, 4, stride=(2,2), padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(16, 64, 4, stride=(1,2), padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, stride=(1,1), padding=1),  \n",
    "            nn.Sigmoid()                \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output\n",
    "\n",
    "model_d = Patch_Discriminator().cuda()\n",
    "criterion_d = nn.BCELoss().cuda()\n",
    "optimizer_d = torch.optim.Adam(model_d.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "scheduler_d = torch.optim.lr_scheduler.StepLR(optimizer_d, step_size=50, gamma=0.3)\n",
    "\n",
    "# Summary of the patch discriminator architecture.\n",
    "summary_d = summary(model_d, input_data=(2, 128, 256))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the Pix2Pix GAN model\n",
    "\n",
    "num = 1;\n",
    "loss_d_count = np.zeros((EPOCH, num))\n",
    "loss_g_count = np.zeros((EPOCH, num))\n",
    "time_count = np.zeros((1, num))\n",
    "\n",
    "for i in range(num):\n",
    "    \n",
    "    time_start=time.time()\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    # Lists to keep track of progress\n",
    "    img_list = []\n",
    "    G_losses = []\n",
    "    D_losses = []\n",
    "    iters = 0\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        for step, (a, b) in enumerate(train_loader):\n",
    "\n",
    "            real_a = avg_real(a.float().cuda())\n",
    "            real_b = b.float().cuda()\n",
    "            fake_b = model_g(a.float().cuda())\n",
    "\n",
    "            #################################\n",
    "            # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
    "            ################################\n",
    "            model_d.zero_grad()\n",
    "\n",
    "            real_cat = torch.cat((real_a, real_b),1)\n",
    "            label = torch.full((real_cat.size(0)*13*13,),real_label)\n",
    "            # Forward pass real batch through D\n",
    "            output = model_d(real_cat).view(-1)\n",
    "            # Calculate loss on all-real batch\n",
    "            loss_d_real = criterion_d(output, label.cuda())\n",
    "            # Calculate gradients for D in backward pass\n",
    "            D_x = output.mean().item()\n",
    "\n",
    "            label.fill_(fake_label)\n",
    "            fake_cat = torch.cat((real_a, fake_b),1)\n",
    "            # Classify all fake batch with D\n",
    "            output = model_d(fake_cat.detach()).view(-1)\n",
    "            # Calculate D's loss on the all-fake batch\n",
    "            loss_d_fake = criterion_d(output, label.cuda())\n",
    "            # Calculate the gradients for this batch\n",
    "            D_G_z1 = output.mean().item()\n",
    "\n",
    "            # Add the gradients from the all-real and all-fake batches\n",
    "            loss_d = (loss_d_real + loss_d_fake) * 0.5\n",
    "            # Update D\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "\n",
    "            #################################\n",
    "            # (2) Update G network: maximize log(D(G(z)))\n",
    "            ################################\n",
    "            model_g.zero_grad()\n",
    "            label.fill_(real_label)\n",
    "            output = model_d(fake_cat).view(-1)\n",
    "\n",
    "            # Calculate G's loss based on this output\n",
    "            loss_gd = criterion_d(output, label.cuda())\n",
    "            loss_gg = criterion_g(fake_cat, real_cat)\n",
    "            loss_g = loss_gd + 100 * loss_gg\n",
    "\n",
    "            # Calculate gradients for G\n",
    "            loss_g.backward()\n",
    "            D_G_z2 = output.mean().item()\n",
    "            # Update G\n",
    "            optimizer_g.step()\n",
    "            \n",
    "        scheduler_d.step()            \n",
    "        scheduler_g.step()\n",
    "        loss_d_count[epoch, i] = loss_d.item()\n",
    "        loss_g_count[epoch, i] = loss_g.item()\n",
    "        \n",
    "        print('Epoch: [%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\t'\n",
    "                      % (epoch, EPOCH, loss_d.item(), loss_g.item()))               \n",
    "        \n",
    "    time_end=time.time()\n",
    "    time_count[0, i] = time_end-time_start\n",
    "    print('time cost',time_count[0, i],'s')\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(loss_g_count[:, i],label=\"G\")\n",
    "    plt.plot(loss_d_count[:, i],label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the well-trained generator's parameter dictionary\n",
    "\n",
    "torch.save(model_g.state_dict(), 'Pix2PixGAN_Patch_G_dict.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
