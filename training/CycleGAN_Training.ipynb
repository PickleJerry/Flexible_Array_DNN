{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Codes for Training the CycleGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.cuda.current_device()\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.device_count()\n",
    "torch.cuda.get_device_name(0)\n",
    "torch.cuda.is_available()\n",
    "\n",
    "import torch\n",
    "import torchvision as tv\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from matplotlib import cm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision.models as models\n",
    "import cv2\n",
    "from numpy import inf\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "import h5py\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data and print its shape\n",
    "\n",
    "mat = h5py.File('ALL_TRAIN_1000.mat', 'r')\n",
    "data = np.array(mat['all_multi_all'])\n",
    "target = np.array(mat['all_envdb_norm_all'])\n",
    "target = np.expand_dims(target, axis=1)\n",
    "\n",
    "print('RAW data: ', data.shape)\n",
    "print('Label images: ', target.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "\n",
    "EPOCH = 200\n",
    "BATCH_SIZE = 4\n",
    "LR = 0.0001        # learning rate\n",
    "\n",
    "torch_data = torch.from_numpy(data)\n",
    "torch_delayed = torch.from_numpy(target)\n",
    "train_dataset = TensorDataset(torch_data, torch_delayed)\n",
    "\n",
    "# DataLoader for easy mini-batch return in training.\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer():\n",
    "    def __init__(self, max_size=50):\n",
    "        assert (max_size > 0), 'Empty buffer or trying to create a black hole. Be careful.'\n",
    "        self.max_size = max_size\n",
    "        self.data = []\n",
    "\n",
    "    def push_and_pop(self, data):\n",
    "        to_return = []\n",
    "        for element in data.data:\n",
    "            element = torch.unsqueeze(element, 0)\n",
    "            if len(self.data) < self.max_size:\n",
    "                self.data.append(element)\n",
    "                to_return.append(element)\n",
    "            else:\n",
    "                if random.uniform(0,1) > 0.5:\n",
    "                    i = random.randint(0, self.max_size-1)\n",
    "                    to_return.append(self.data[i].clone())\n",
    "                    self.data[i] = element\n",
    "                else:\n",
    "                    to_return.append(element)\n",
    "        return Variable(torch.cat(to_return))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CycleGAN generator A implementation\n",
    "\n",
    "class Generator_A(nn.Module):\n",
    "    \n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=3, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    # torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Sigmoid(),\n",
    "                    )\n",
    "            return block\n",
    "        \n",
    "    def bottle_neck(self, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=256, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=512, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Generator_A, self).__init__()\n",
    "        #Encode\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.bottle_neck()\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_pool1 = self.dropout(encode_pool1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_pool2 = self.dropout(encode_pool2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        encode_pool3 = self.dropout(encode_pool3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        decode_block3 = self.dropout(decode_block3)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        decode_block2 = self.dropout(decode_block2)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        decode_block1 = self.dropout(decode_block1)\n",
    "        final_layer = self.final_layer(decode_block1)        \n",
    "        return  final_layer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CycleGAN generator B implementation\n",
    "\n",
    "class Generator_B(nn.Module):\n",
    "    \n",
    "    def contracting_block(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=out_channels, out_channels=out_channels, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.ReLU(),\n",
    "                )\n",
    "        return block\n",
    "    \n",
    "    def expansive_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=mid_channel, out_channels=out_channels, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def final_block(self, in_channels, mid_channel, out_channels, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=in_channels, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=mid_channel, out_channels=mid_channel, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(mid_channel),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=3, in_channels=mid_channel, out_channels=out_channels, padding=1),\n",
    "                    # torch.nn.BatchNorm2d(out_channels),\n",
    "                    torch.nn.Sigmoid(),\n",
    "                    )\n",
    "            return block\n",
    "        \n",
    "    def bottle_neck(self, kernel_size=3, padding=1):\n",
    "            block = torch.nn.Sequential(\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=256, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.Conv2d(kernel_size=kernel_size, in_channels=512, out_channels=512, padding=padding),\n",
    "                    torch.nn.BatchNorm2d(512),\n",
    "                    torch.nn.ReLU(),\n",
    "                    torch.nn.ConvTranspose2d(in_channels=512, out_channels=256, kernel_size=kernel_size, stride=2, padding=padding, output_padding=1)\n",
    "                    )\n",
    "            return block\n",
    "    \n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(Generator_B, self).__init__()\n",
    "        #Encode\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        self.conv_encode1 = self.contracting_block(in_channels=in_channel, out_channels=64)\n",
    "        self.conv_maxpool1 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode2 = self.contracting_block(64, 128)\n",
    "        self.conv_maxpool2 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        self.conv_encode3 = self.contracting_block(128, 256)\n",
    "        self.conv_maxpool3 = torch.nn.MaxPool2d(kernel_size=2)\n",
    "        # Bottleneck\n",
    "        self.bottleneck = self.bottle_neck()\n",
    "        # Decode\n",
    "        self.conv_decode3 = self.expansive_block(512, 256, 128)\n",
    "        self.conv_decode2 = self.expansive_block(256, 128, 64)\n",
    "        self.final_layer = self.final_block(128, 64, out_channel)\n",
    "        \n",
    "    def crop_and_concat(self, upsampled, bypass, crop=False):\n",
    "        if crop:\n",
    "            c = (bypass.size()[2] - upsampled.size()[2]) // 2\n",
    "            bypass = F.pad(bypass, (-c, -c, -c, -c))\n",
    "        return torch.cat((upsampled, bypass), 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Encode\n",
    "        encode_block1 = self.conv_encode1(x)\n",
    "        encode_pool1 = self.conv_maxpool1(encode_block1)\n",
    "        encode_pool1 = self.dropout(encode_pool1)\n",
    "        encode_block2 = self.conv_encode2(encode_pool1)\n",
    "        encode_pool2 = self.conv_maxpool2(encode_block2)\n",
    "        encode_pool2 = self.dropout(encode_pool2)\n",
    "        encode_block3 = self.conv_encode3(encode_pool2)\n",
    "        encode_pool3 = self.conv_maxpool3(encode_block3)\n",
    "        encode_pool3 = self.dropout(encode_pool3)\n",
    "        # Bottleneck\n",
    "        bottleneck1 = self.bottleneck(encode_pool3)\n",
    "        # Decode\n",
    "        decode_block3 = self.crop_and_concat(bottleneck1, encode_block3, crop=True)\n",
    "        decode_block3 = self.dropout(decode_block3)\n",
    "        cat_layer2 = self.conv_decode3(decode_block3)\n",
    "        decode_block2 = self.crop_and_concat(cat_layer2, encode_block2, crop=True)\n",
    "        decode_block2 = self.dropout(decode_block2)\n",
    "        cat_layer1 = self.conv_decode2(decode_block2)\n",
    "        decode_block1 = self.crop_and_concat(cat_layer1, encode_block1, crop=True)\n",
    "        decode_block1 = self.dropout(decode_block1)\n",
    "        final_layer = self.final_layer(decode_block1)\n",
    "        \n",
    "        return  final_layer    \n",
    "    \n",
    "model_g_a = Generator_A(in_channel=128, out_channel=1).cuda()\n",
    "model_g_b = Generator_B(in_channel=1, out_channel=128).cuda()\n",
    "\n",
    "criterion_g = nn.L1Loss().cuda()\n",
    "optimizer_g_a = torch.optim.Adam(model_g_a.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "optimizer_g_b = torch.optim.Adam(model_g_b.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "scheduler_g_a = torch.optim.lr_scheduler.StepLR(optimizer_g_a, step_size=50, gamma=0.3)\n",
    "scheduler_g_b = torch.optim.lr_scheduler.StepLR(optimizer_g_b, step_size=50, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CycleGAN [patch] discriminator A&B implementation\n",
    "\n",
    "class Discriminator_A(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_A, self).__init__()\n",
    "        self.main = nn.Sequential(  \n",
    "            nn.Conv2d(1, 16, 4, stride=(2,2), padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(16, 64, 4, stride=(1,2), padding=1),  \n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, stride=(1,1), padding=1),  \n",
    "            nn.Sigmoid()                \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output\n",
    "\n",
    "    \n",
    "class Discriminator_B(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator_B, self).__init__()\n",
    "        self.main = nn.Sequential(  \n",
    "            nn.Conv2d(128, 64, 4, stride=(2,2), padding=1), \n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(64, 128, 4, stride=(1,2), padding=1),  \n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(128, 256, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, 256, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(256, 512, 4, stride=(2,2), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 512, 4, stride=(1,1), padding=1),  \n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Conv2d(512, 1, 4, stride=(1,1), padding=1),  \n",
    "            nn.Sigmoid()                \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        output = self.main(x)\n",
    "        return output    \n",
    "    \n",
    "model_d_a = Discriminator_A().cuda()\n",
    "model_d_b = Discriminator_B().cuda()\n",
    "\n",
    "criterion_d = nn.BCELoss().cuda()\n",
    "optimizer_d_a = torch.optim.Adam(model_d_a.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "optimizer_d_b = torch.optim.Adam(model_d_b.parameters(), lr=LR, betas=(0.5, 0.999), weight_decay=1e-5)\n",
    "scheduler_d_a = torch.optim.lr_scheduler.StepLR(optimizer_d_a, step_size=50, gamma=0.3)\n",
    "scheduler_d_b = torch.optim.lr_scheduler.StepLR(optimizer_d_b, step_size=50, gamma=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the CycleGAN model\n",
    "\n",
    "num = 1;\n",
    "loss_da_count = np.zeros((EPOCH, num))\n",
    "loss_db_count = np.zeros((EPOCH, num))\n",
    "loss_ga_count = np.zeros((EPOCH, num))\n",
    "loss_gb_count = np.zeros((EPOCH, num))\n",
    "time_count = np.zeros((1, num))\n",
    "\n",
    "for i in range(num):\n",
    "   \n",
    "    time_start=time.time()\n",
    "    real_label = 1\n",
    "    fake_label = 0\n",
    "    # Lists to keep track of progress\n",
    "    img_list = []\n",
    "    G_A_losses = []\n",
    "    G_B_losses = []\n",
    "    D_A_losses = []\n",
    "    D_B_losses = []\n",
    "    Cycle_A_losses = []\n",
    "    Cycle_B_losses = []\n",
    "    iters = 0\n",
    "\n",
    "    fake_A_buffer = ReplayBuffer()\n",
    "    fake_B_buffer = ReplayBuffer()\n",
    "\n",
    "    for epoch in range(EPOCH):\n",
    "        epoch_start_time = time.time()\n",
    "        for step, (a, b) in enumerate(train_loader):\n",
    "\n",
    "            real_a = Variable(a.float().cuda())\n",
    "            real_b = Variable(b.float().cuda())\n",
    "            label = torch.full((real_b.size(0)*13*13,),real_label)\n",
    "\n",
    "            ###################################\n",
    "            #  Update Generator network\n",
    "            ##################################\n",
    "            optimizer_g_a.zero_grad()\n",
    "\n",
    "            # generate real A to fake B; D_A(G_A(A))\n",
    "            fake_b = model_g_a(real_a)\n",
    "            result_d_a = model_d_a(fake_b).view(-1)\n",
    "            loss_g_a = criterion_d(result_d_a, label.cuda())\n",
    "            # reconstruct fake B to rec A; G_B(G_A(A))\n",
    "            recon_a = model_g_b(fake_b)\n",
    "            cycleloss_a = criterion_g(recon_a, real_a) * 50\n",
    "            loss_ga = loss_g_a + cycleloss_a\n",
    "            \n",
    "            # Update G\n",
    "            loss_ga.backward()\n",
    "            optimizer_g_a.step()\n",
    "\n",
    "            # generate real B to fake A; D_A(G_B(B))\n",
    "            fake_a = model_g_b(real_b)\n",
    "            result_d_b = model_d_b(fake_a).view(-1)\n",
    "            loss_g_b = criterion_d(result_d_b, label.cuda())\n",
    "            # reconstruct fake A to rec B G_A(G_B(B))\n",
    "            recon_b = model_g_a(fake_a)\n",
    "            cycleloss_b = criterion_g(recon_b, real_b) * 50\n",
    "            # loss_g = loss_g_a + loss_g_b + cycleloss_a + cycleloss_b\n",
    "            loss_gb = loss_g_b + cycleloss_b\n",
    "\n",
    "            # Update G\n",
    "            loss_gb.backward()\n",
    "            optimizer_g_b.step()\n",
    "\n",
    "            ###################################\n",
    "            #  Update Discriminator A network\n",
    "            ##################################\n",
    "            optimizer_d_a.zero_grad()\n",
    "\n",
    "            # train discriminator D_A\n",
    "            real_d_a = model_d_a(real_b).view(-1)\n",
    "            loss_d_a_real = criterion_d(real_d_a, label.cuda())\n",
    "            label.fill_(fake_label)\n",
    "            # fake_b = fake_A_buffer.push_and_pop(fake_b)\n",
    "            fake_d_a= model_d_a(fake_b.detach()).view(-1)\n",
    "            loss_d_a_fake = criterion_d(fake_d_a, label.cuda())\n",
    "            loss_d_a = (loss_d_a_real + loss_d_a_fake) * 0.5\n",
    "\n",
    "            # Update D_A\n",
    "            loss_d_a.backward()\n",
    "            optimizer_d_a.step()       \n",
    "\n",
    "            ###################################\n",
    "            #  Update Discriminator B network\n",
    "            ################################## \n",
    "            optimizer_d_b.zero_grad()\n",
    "\n",
    "            # train discriminator D_B\n",
    "            label.fill_(real_label)\n",
    "            # fake_a = fake_A_buffer.push_and_pop(fake_a)\n",
    "            real_d_b = model_d_b(real_a).view(-1)\n",
    "            loss_d_b_real = criterion_d(real_d_b, label.cuda())\n",
    "            label.fill_(fake_label)\n",
    "            fake_d_b= model_d_b(fake_a.detach()).view(-1)\n",
    "            loss_d_b_fake = criterion_d(fake_d_b, label.cuda())\n",
    "            loss_d_b = (loss_d_b_real + loss_d_b_fake) * 0.5\n",
    "\n",
    "            # Update D_B\n",
    "            loss_d_b.backward()\n",
    "            optimizer_d_b.step() \n",
    "\n",
    "        scheduler_d_a.step()            \n",
    "        scheduler_g_a.step()\n",
    "        scheduler_d_b.step()            \n",
    "        scheduler_g_b.step()\n",
    "        \n",
    "        loss_da_count[epoch, i] = loss_d_a.item()\n",
    "        loss_db_count[epoch, i] = loss_d_b.item()\n",
    "        loss_ga_count[epoch, i] = loss_g_a.item()\n",
    "        loss_gb_count[epoch, i] = loss_g_b.item()\n",
    "\n",
    "        print('Epoch: [%d/%d]\\t Loss_DA: %.4f, Loss_DB: %.4f, Loss_GA: %.4f, Loss_GB: %.4f, Loss_CA: %.4f, Loss_CB: %.4f'\n",
    "              % (epoch, EPOCH, loss_d_a.item(), loss_d_b.item(), loss_g_a.item(), loss_g_b.item(), cycleloss_a.item(), cycleloss_b.item()))        \n",
    "        \n",
    "    time_end=time.time()\n",
    "    time_count[0, i] = time_end-time_start\n",
    "    print('time cost',time_count[0, i],'s')\n",
    "    \n",
    "    plt.figure(figsize=(6,3))\n",
    "    plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "    plt.plot(loss_ga_count[:, i],label=\"G_A\")\n",
    "    plt.plot(loss_gb_count[:, i],label=\"G_B\")\n",
    "    plt.plot(loss_da_count[:, i],label=\"D_A\")\n",
    "    plt.plot(loss_db_count[:, i],label=\"D_B\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the well-trained generator A's parameter dictionary\n",
    "\n",
    "torch.save(model_g_a.state_dict(), 'CycleGAN_Patch_GA_dict.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
